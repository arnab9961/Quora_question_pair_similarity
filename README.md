# ğŸ“Œ Question Pair Similarity Classification

## **Introduction**  
This project aims to build a **machine learning system** that can identify whether two questions have the **same meaning** or not. Using **text processing, data analysis, and machine learning models**, we compare question pairs to detect duplicates.

---

## **ğŸ“‚ 1. Reading the Dataset**  
The dataset contains **404,290 question pairs**, but training on the full dataset requires too much time.  
âœ… To optimize performance, we **randomly selected 50,000 rows** for training.  

---

## **ğŸ“Š 2. Exploratory Data Analysis (EDA)**  
Before training the model, we analyzed the data:  
âœ… Checked the **number of duplicate questions**.  
âœ… Used **graphs and charts** to visualize word distributions.  

---

## **ğŸ” 3. Text Preprocessing**  
Since raw text contains **noise**, we cleaned the questions using:  
âœ… **Removing HTML tags & punctuation**  
âœ… **Converting text to lowercase**  
âœ… **Removing stopwords** (e.g., "is", "the", "a")  
âœ… **Lemmatization** (e.g., "running" â†’ "run")  
âœ… **Replacing special characters** (e.g., "$" â†’ "dollar")  

---

## **âš™ï¸ 4. Feature Engineering**  
We added extra features to help the model understand **question similarities**:  
âœ… **Basic Features:** Question length, word count, and shared words.  
âœ… **Token-based Features:** Checked if questions start or end with the same word.  
âœ… **Fuzzy Matching Features:** Compared phrase similarity.  
âœ… **TF-IDF Vectorization:** Converted text into numerical features for model training.  

---

## **ğŸ¤– 5. Model Building & Training**  
The dataset was split into:  
âœ… **80% Training Data**  
âœ… **20% Test Data**  

We tested multiple machine learning models:  
âœ… **Logistic Regression**  
âœ… **Random Forest**  
âœ… **XGBoost (XGB)**  
âœ… **Decision Tree**  
âœ… **Artificial Neural Network (ANN) using Keras**  
âœ… **LSTM for sequence-based learning**  

We also performed **Grid Search** for **hyperparameter tuning**.  

---

## **ğŸ“ˆ 6. Model Evaluation**  

| **Model**              | **Accuracy** | **F1-Score** |
|------------------------|-------------|--------------|
| Logistic Regression   | **76.24%**   | **66.42%**   |
| Random Forest        | **77.88%**   | **68.42%**   |
| XGB                  | **77.50%**   | **68.80%**   |
| ANN                  | **72.70%**   | **62.29%**   |
| Decision Tree        | **72.70%**   | **62.29%**   |

âœ… **Random Forest performed the best**, achieving **77.88% accuracy**.  
âœ… A **confusion matrix** was used to analyze model errors.  

---

## **ğŸš€ 7. Deployment**  
We deployed the model using **Streamlit**, allowing users to:  
âœ… Enter **two questions**  
âœ… Get a **similarity probability score**  

ğŸ”— **Try the Web App:** [ğŸ‘‰ Click Here](https://questionquora.streamlit.app/)  

![Application Screenshot](image.png)  
